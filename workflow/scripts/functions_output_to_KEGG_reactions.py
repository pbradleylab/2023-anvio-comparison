#!/usr/bin/python
# a script for mapping KO annotations to KEGG reaction IDs for plotting (ie, with ggkegg)
# designed to work with the output directories generated by the Snakemake workflow
# input: comma-separated list of folders containing the functions output files; 
#        a tsv file listing the genomes to work with (prefix of the file names, which for us is genome accession numbers); 
#        path to anvi'o MODULES.db file (for determining which KOs are associated with reactions)
# output: two tables, one including KOs associated with KEGG reactions and one for those not associated with reactions. 
#         they contain Boolean columns to indicate which tool(s) have annotated each KO in the provided genomes
# usage: python functions_output_to_KEGG_reaactions.py [TARGET_FOLDER(S)] [GENOMES_FILE] [MODULES_DB]

import os
import sys
import argparse
import pandas as pd

import anvio
from anvio import kegg

# COMMAND LINE PARAMETERS
if len(sys.argv) < 4:
    print("USAGE ERROR: not enough command-line arguments\n" +
          "python functions_output_to_KEGG_reactions.py [TARGET_FOLDER(S)] [GENOMES_FILE] [MODULES_DB]")
    sys.exit(1)
## comma-separated list of folders where all functions output is sorted by genome accession
target_dataset_folders = sys.argv[1]
## file of genome accessions to work with (these accessions are used in the functions file names)
genome_info_file = sys.argv[2]
## path to the KEGG modules database generated and used by anvi'o
mod_db_path = sys.argv[3]

# CONSTANTS
TOOL_LIST = ['anvio', 'kofamscan', 'microbeannotator', 'eggnog']
PARAM_LIST = ['default', 'no_hueristic', 'stray', 'refined']

# METHODS to parse functions output from each tool
def parse_anvio_functions(file_path, keep_best_hit_per_gene=True):
    """Parses output from anvi-export-functions that is provided via file path. 
       Returns set of unique KO annotations identified by the tool.
    """

    df = pd.read_csv(file_path, sep="\t")
    df = df[df.source == 'KOfam']
    if keep_best_hit_per_gene:
        # keep hit with lowest e-value per gene
        df = df.sort_values('e_value').drop_duplicates('gene_callers_id', keep='first')
    return set(df.accession)

def parse_kofamscan_functions(file_path, keep_best_hit_per_gene=True):
    """Parses 'detail-tsv' format output from kofamscan that is provided via file path.
       Returns set of unique KO annotations identified by the tool. Only returns those KOs whose bitscore was higher
       than the threshold (asterisk in first column of table).
    """

    df = pd.read_csv(file_path, sep="\t", comment="#", \
                     names = ['passes_threshold','gene','KO','thrshld','score','evalue','definition'])
    df = df[df.passes_threshold == "*"]
    if keep_best_hit_per_gene:
        # keep hit with lowest e-value per gene
        df = df.sort_values('evalue').drop_duplicates('gene', keep='first')
    return set(df.KO)

def parse_microbeannotator_functions(file_path):
    """Parses the *.faa.annot output from MicrobeAnnotator that is provided via file path.
       Returns set of unique KO annotations identified by the tool.
    """

    df = pd.read_csv(file_path, sep="\t")
    return set(df[df.ko_number.notna()].ko_number)

def parse_eggnog_functions(file_path):
    """Parses the *.emapper.annotations output from EggNOG-Mapper that is provided via file path.
       Returns set of unique KO annotations identified by the tool.
    """

    df = pd.read_csv(file_path, sep="\t", comment="#", \
                     names = ["query","seed_ortholog","evalue","score","eggNOG_OGs","max_annot_lvl","COG_category","Description","Preferred_name","GOs","EC","KEGG_ko","KEGG_Pathway","KEGG_Module","KEGG_Reaction","KEGG_rclass","BRITE","KEGG_TC","CAZy","BiGG_Reaction","PFAMs"])
    ko_list = df[df.KEGG_ko.str.contains('ko')].KEGG_ko.str.replace("ko:", "").tolist()
    ko_list = [x for k in ko_list for x in k.split(',')]
    return set(ko_list)

# CONSTANTS
FUNC_FILE_SUFFIX = ".tsv"

print(f"Analyzing genomes from... {genome_info_file}")
print(f"Modules database......... {mod_db_path}")
args = argparse.Namespace()
db = kegg.ModulesDatabase(mod_db_path, args)

genome_info = pd.read_csv(genome_info_file, sep="\t")
acc_list = genome_info.sample_name.to_list()

target_dataset_list = target_dataset_folders.split(",")

ko_annotations = {tf: set([])  for tf in target_dataset_list}
reaction_dict = {}
kos_without_reactions = {}

for tf in target_dataset_list:
    print(f"Parsing modules from input folder............. {tf}")
    path_fields = tf.split('/')

    # find out which tool's output we are processing
    tool_string = None
    param_string = None
    for i,f in enumerate(path_fields):
        if f in TOOL_LIST:
            tool_string = f
        if f in PARAM_LIST:
            param_string = f
        
    if tool_string == "eggnog":
        param_string = "default"
    
    if not tool_string or not param_string:
        print(f"ERROR: cannot parse tool/parameter strings from path {tf}")
        sys.exit(2)
    print(f"Tool: {tool_string}\nParameter set: {param_string}")

    # get list of all KO annotations identified in at least one genome by this tool/param combo
    ko_set = set([])
    for a in acc_list:
        func_file_path = os.path.join(tf, a + FUNC_FILE_SUFFIX)
        if tool_string == 'anvio':
            ko_set.update(parse_anvio_functions(func_file_path))
        elif tool_string == 'kofamscan':
            ko_set.update(parse_kofamscan_functions(func_file_path))
        elif tool_string == "microbeannotator":
            func_file_path = os.path.join(tf, a, "annotation_results", a + ".faa.annot")
            ko_set.update(parse_microbeannotator_functions(func_file_path))
        elif tool_string == "eggnog":
            func_file_path = os.path.join(tf, a + ".emapper.annotations")
            ko_set.update(parse_eggnog_functions(func_file_path))
        else:
            print(f"ERROR. No function defined for processing tool '{tool_string}'.")
            sys.exit(1)

    num_kos = len(ko_set)
    print(f"{num_kos} unique KO annotations identified by {tool_string} ({param_string})")

    # get the reactions associated with each KO
    annotation_string = f"annotated_by_{tool_string}_{param_string}"
    for k in ko_set:
        r_list = db.get_ko_reactions_from_modules_table(k)
        if not r_list:
            if k in kos_without_reactions:
                kos_without_reactions[k][annotation_string] = True
            else:
                kos_without_reactions[k] = {annotation_string: True}
            continue
        for r in r_list:
            r_acc = r.replace("RN", "rn"); # make it compatible with the lowercase reaction IDs in the tbl_graph in R
            if r_acc in reaction_dict:
                reaction_dict[r_acc]['associated_KOs'].add(k)
                reaction_dict[r_acc][annotation_string] = True
            else:
                reaction_dict[r_acc] = {'associated_KOs': set([k]), annotation_string: True}

rdf = pd.DataFrame(reaction_dict).T
rdf.index.rename('reaction', inplace=True)
rdf.associated_KOs = rdf['associated_KOs'].apply(lambda x: ','.join(x))
rdf.fillna(False, inplace=True)

r_output_file = f"combined_reaction_table.txt"
if len(target_dataset_list) == 1:
    tool_string = target_dataset_list[0].replace(DATASET_FOLDER_SUFFIX, "").replace("/", "")
    r_output_file = f"{tool_string}_reaction_table.txt"
    m_output_file = f"{tool_string}_modules.txt"
rdf.to_csv(r_output_file, sep="\t")
print(f"Reaction output file............. {r_output_file}")

kdf = pd.DataFrame(kos_without_reactions).T
kdf.index.rename('KO', inplace=True)
kdf.fillna(False, inplace=True)
k_output_file = f"combined_kos_without_reaction.txt"
kdf.to_csv(k_output_file, sep="\t")
print(f"Output for KOs without associated reactions............. {k_output_file}")